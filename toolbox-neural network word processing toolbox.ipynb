{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"toolbox-neural network word processing toolbox.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KrBpvZj-_DOV","slideshow":{"slide_type":"slide"}},"source":["# Neural Network word processing toolbox\n","\n","\n","Originally used in project: [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PACDfTOlieOS","colab_type":"text"},"source":["## Load embeddings"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0uzFIZXVmBU0","colab":{}},"source":["# Assign coefficient to word\n","def get_coefs(word, *arr):\n","    return word, np.asarray(arr, dtype='float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cV-attBLmBU2","colab":{}},"source":["# Load embeddings from a file path and assign coefficients\n","def load_embeddings(path):\n","    with open(path) as f:\n","        return dict(get_coefs(*line.strip().split(' ')) for line in f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L2lUAsHnig0x","colab_type":"code","colab":{}},"source":["filepath_crawl = '/tmp/crawl-300d-2M.vec'\n","embeddings_crawl = load_embeddings(filepath_crawl)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wfyfVl-2pG5-","colab_type":"text"},"source":["## Check vocabulary and word coverage\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"xkkVTcaArEbr","colab_type":"code","colab":{}},"source":["def build_vocab(texts):\n","    \"\"\"\n","    Build vocabulary from an array of strings\n","    Counts number of apparatitions of each word in the entire array.\n","    \n","    @args:\n","    - texts = array of strings\n","    \n","    @returns dictionary of word / occurences\n","    \"\"\"\n","    sentences = texts.apply(lambda x: x.split()).values\n","    vocab = {}\n","    for sentence in sentences:\n","        for word in sentence:\n","            try:\n","                vocab[word] += 1\n","            except KeyError:\n","                vocab[word] = 1\n","    return vocab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gew3CjKbrEbt","colab_type":"code","colab":{}},"source":["def check_coverage(vocab, embeddings_index):\n","    \"\"\"\n","    Looks for each word in a vocabulary in a word embeddings index\n","    \n","    @args:\n","    - vocab: vocabulary (dictionary of word / occurences)\n","    - embeddings_index\n","    \n","    @returns: dictionary of unrecognized words and number of occurences\n","    \"\"\"\n","    known_words = {}\n","    unknown_words = {}\n","    nb_known_words = 0\n","    nb_unknown_words = 0\n","    for word in vocab.keys():\n","        try:\n","            known_words[word] = embeddings_index[word]\n","            nb_known_words += vocab[word]\n","        except:\n","            unknown_words[word] = vocab[word]\n","            nb_unknown_words += vocab[word]\n","            pass\n","\n","    print('Found embeddings for {:.3%} of vocab'.format(len(known_words) / len(vocab)))\n","    print('Found embeddings for  {:.3%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n","    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n","\n","    return unknown_words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2zgtz6MrEb0","colab_type":"code","colab":{}},"source":["# Check coverage of each embedding(s)\n","oov_crawl = check_coverage(vocab, embeddings_crawl)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwCgQXQGrEb5","colab_type":"text"},"source":["## Clean contractions"]},{"cell_type":"code","metadata":{"id":"d-MLEoqCrEcB","colab_type":"code","colab":{}},"source":["# Map the missing contractions\n","def clean_contractions(text, mapping):\n","    specials = [\"’\", \"‘\", \"´\", \"`\"]\n","    for s in specials:\n","        text = text.replace(s, \"'\")\n","    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HOanJxqShC-k","colab_type":"code","colab":{}},"source":["# Clean contractions\n","train['comment_text'] = train['comment_text'].apply(lambda x: clean_contractions(x, CONTRACTION_LOOKUP_EN))"],"execution_count":0,"outputs":[]}]}